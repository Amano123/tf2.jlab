{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import glob\n",
    "import re\n",
    "import io \n",
    "import os\n",
    "\n",
    "file_name_path = \"./jsai/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのy意味込み\n",
    "import requests\n",
    "\n",
    "# メッセージ送信、画像送信、スタンプ送信の処理をクラス化\n",
    "class LINENotifyBot:\n",
    "    API_URL = 'https://notify-api.line.me/api/notify'\n",
    "    def __init__(self, access_token):\n",
    "        self.__headers = {'Authorization': 'Bearer ' + access_token}\n",
    "\n",
    "    def send(\n",
    "            self, message,\n",
    "            image=None, sticker_package_id=None, sticker_id=None,\n",
    "            ):\n",
    "        payload = {\n",
    "            'message': message,\n",
    "            'stickerPackageId': sticker_package_id,\n",
    "            'stickerId': sticker_id,\n",
    "            }\n",
    "        files = {}\n",
    "        if image != None:\n",
    "            files = {'imageFile': open(image, 'rb')}\n",
    "        r = requests.post(\n",
    "            LINENotifyBot.API_URL,\n",
    "            headers=self.__headers,\n",
    "            data=payload,\n",
    "            files=files,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = LINENotifyBot(access_token='luTtDSuF8bgeUBZoPDyA6s44vHlQO2ptwIWGM8dW7Yp')\n",
    "def LINE(text):\n",
    "    bot.send(message=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir(file_name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_create(file_name_path, file_names):\n",
    "    '''\n",
    "    dict_create\n",
    "    * file_name_path :root path\n",
    "    * file_names     :file name list\n",
    "    ファイルの読み込みをわかりやすくするために辞書型のデータを作成\n",
    "    フォルダ名：ファイル名の関係にしてある\n",
    "    '''\n",
    "    data_dict = {}\n",
    "    for name in file_names:\n",
    "        if os.path.isdir(file_name_path + name):\n",
    "            #data_dict[name] = glob.glob(file_name_path + name + \"/txt/*.txt\")\n",
    "            name_list = os.listdir(file_name_path + name + \"/txt/\")\n",
    "            data_dict[name] = [i for i in name_list if i[-4:] == \".txt\"]\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting():\n",
    "    settings = {\n",
    "        \"settings\": {\n",
    "            \"analysis\": {\n",
    "                \"filter\": {\n",
    "                    \"synonyms_filter\": { # 同義語フィルターの定義\n",
    "                        \"type\": \"synonym\",\n",
    "                        \"synonyms\": [ #同義語リストの定義 (今は空の状態)\n",
    "                            ]\n",
    "                    }\n",
    "                },\n",
    "                \"tokenizer\": {\n",
    "                    \"sudachi_tokenizer\": {\n",
    "                        \"type\": \"sudachi_tokenizer\",\n",
    "                        \"discard_punctuation\": True,\n",
    "                        \"sudachi_split\": \"search\",\n",
    "                        \"resources_path\": \"/usr/share/elasticsearch/config/sudachi\",\n",
    "                        \"settings_path\": \"/usr/share/elasticsearch/config/sudachi/sudachi_fulldict.json\"\n",
    "                    }\n",
    "                },\n",
    "                \"analyzer\": {\n",
    "                    \"sudachi_analyzer\": {\n",
    "                        \"char_filter\": [\n",
    "                            \"icu_normalizer\", # 文字単位の正規化\n",
    "                            \"kuromoji_iteration_mark\" # 繰り返し文字の正規化\n",
    "                        ],\n",
    "                        \"filter\": [\n",
    "                            \"synonyms_filter\", # 同義語展開\n",
    "                            # \"kuromoji_baseform\", # 活用語の原型化\n",
    "                            # \"kuromoji_part_of_speech\", # 不要品詞の除去\n",
    "                            # \"ja_stop\", #不要単語の除去\n",
    "                            \"kuromoji_number\", # 数字の正規化\n",
    "                            \"kuromoji_stemmer\" #長音の正規化\n",
    "                        ],\n",
    "                        \"tokenizer\": \"sudachi_tokenizer\",\n",
    "                        \"type\": \"custom\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"category\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "                \"title\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "                \"text\": {\n",
    "                    \"analyzer\": \"sudachi_analyzer\",\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                \"sudachi\": {\n",
    "                    \"type\": \"text\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_es(index_name, es_host_name, setting):\n",
    "    es = Elasticsearch(es_host_name)\n",
    "    if es.indices.exists(index=index_name):\n",
    "        print(f\"{index_name}を更新します。\")\n",
    "        es.indices.delete(index=index_name)\n",
    "    result = es.indices.create(index=index_name, body=setting)\n",
    "    if result[\"acknowledged\"]:\n",
    "        print(f'create index【{result[\"index\"]}】')\n",
    "        return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jsai_datasetを更新します。\n",
      "create index【jsai_dataset】\n"
     ]
    }
   ],
   "source": [
    "data_dict = dict_create(file_name_path, file_names)\n",
    "es_name = \"jsai_dataset\"\n",
    "es_host_name = \"elasticsearch-sudachi\"\n",
    "es = create_es(es_name, es_host_name, setting())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_word(text):\n",
    "    # 文末の改行を削除\n",
    "    text_data = re.sub(\"\\n+$\", \"\", text)\n",
    "    text_data = text_data.split(\",\")\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_datas(es, index_name, category, file_names):\n",
    "    for name in file_names:\n",
    "        original_data = io.open(f\"./jsai/{category}/txt/{name}\",mode=\"r\", encoding=\"utf-8\").read()\n",
    "        datas = stop_word(original_data)\n",
    "        for num, data in enumerate(datas, 1):\n",
    "            print(f\"\\r{category}:{name[:-4]} {num}\", end=\"\")\n",
    "            analyze_body = {\"text\": data, \"analyzer\": \"sudachi_analyzer\"}\n",
    "            sudachi_morp = es.indices.analyze(index=index_name, body=analyze_body)[\"tokens\"]\n",
    "            sudachi_token = \" \".join([word[\"token\"] for word in sudachi_morp])\n",
    "            body = {\n",
    "                \"category\": category,\n",
    "                \"title\": name[:-4],\n",
    "                \"text\": data,\n",
    "                \"sudachi\": sudachi_token\n",
    "            }\n",
    "            es.index(index=index_name, body=body)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "メディアミックス:ジュラシック・パーク 45バース 5 27 697\n",
      "finished メディアミックス\n",
      "アニメ:がきデカ 305fe 8レラガールズ (アニメ) 34ana Famiglia- 138\n",
      "finished アニメ\n",
      "公開企業:カーリットホールディングス 6ン 2116ク・カンパニー 6\n",
      "finished 公開企業\n",
      "食品:ハーリング (料理) 940゙ 10\n",
      "finished 食品\n",
      "アーティスト:ボストン (バンド) 15ニー 6・バンド 12 6ates of America 4\n",
      "finished アーティスト\n",
      "おもちゃ:メリーゴーラウンド 86ラー 5\n",
      "finished おもちゃ\n",
      "ゲーム:シャドウハンターズ 12ンカードゲーム 1\n",
      "finished ゲーム\n",
      "バイク:デグナー 30 25 607ーグ) 23on 9の科学者・成海朔の挑戦〜 6ER 3\n",
      "finished バイク\n",
      "ドリンク:ポスカ (飲料) 5 8スキー) 11\n",
      "finished ドリンク\n",
      "自動車:ベントレー・4¼リットル 954 24 4\n",
      "finished 自動車\n"
     ]
    }
   ],
   "source": [
    "for category in data_dict:\n",
    "    input_datas(es, es_name, category, data_dict[category])\n",
    "    print(f\"finished {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "メディアミックス\n",
      "total {'value': 5812, 'relation': 'eq'}\n",
      "アニメ\n",
      "total {'value': 4030, 'relation': 'eq'}\n",
      "公開企業\n",
      "total {'value': 2721, 'relation': 'eq'}\n",
      "食品\n",
      "total {'value': 657, 'relation': 'eq'}\n",
      "アーティスト\n",
      "total {'value': 4953, 'relation': 'eq'}\n",
      "おもちゃ\n",
      "total {'value': 516, 'relation': 'eq'}\n",
      "ゲーム\n",
      "total {'value': 814, 'relation': 'eq'}\n",
      "バイク\n",
      "total {'value': 10000, 'relation': 'gte'}\n",
      "ドリンク\n",
      "total {'value': 154, 'relation': 'eq'}\n",
      "自動車\n",
      "total {'value': 372, 'relation': 'eq'}\n"
     ]
    }
   ],
   "source": [
    "for category in data_dict:\n",
    "    print(category)\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"term\": {\n",
    "                \"category\": category\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    result = es.search(\n",
    "            index=es_name,\n",
    "            body=body\n",
    "    )\n",
    "    print('total', result['hits']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in data_dict:\n",
    "    LINE(f\"\\n{category} start\")\n",
    "    response = es.search(\n",
    "                    scroll='2m',\n",
    "                    size=10000,\n",
    "                    index=es_name,\n",
    "                    body={\n",
    "                        \"query\": {\n",
    "                            \"term\": {\n",
    "                                \"category\": category\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "    sid = response['_scroll_id']\n",
    "    # print('sid', sid)\n",
    "    # print('total', response['hits']['total'])\n",
    "\n",
    "    scroll_size = len(response['hits']['hits'])\n",
    "    # print('scroll_size', scroll_size)\n",
    "    open(f\"./sudachi_dataset/{category}.txt\", mode=\"x\", encoding=\"utf-8\")\n",
    "    counter = 1\n",
    "    while True:\n",
    "        # スクロールサイズ 0 だったら終了\n",
    "        if scroll_size <= 0:\n",
    "            break\n",
    "\n",
    "        # 検索結果を処理\n",
    "    #     get_doc(response['hits']['hits'])\n",
    "        hits = response['hits']['hits']\n",
    "        for hit in hits:\n",
    "            text = hit['_source']['sudachi']\n",
    "#             print(f\"{counter} {text}\", end=\"\")\n",
    "            with open(f\"./sudachi_dataset/{category}.txt\", mode=\"a\", encoding=\"utf-8\") as save_file:\n",
    "                save_file.write(text + \"\\n\")\n",
    "            counter += 1\n",
    "\n",
    "        # スクロールから次の検索結果取得\n",
    "        response = es.scroll(scroll_id=sid, scroll='10m')\n",
    "        scroll_size = len(response['hits']['hits'])\n",
    "    #     print('scroll_size', scroll_size)\n",
    "    LINE(f\"\\n{category} end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "while True:\n",
    "    # スクロールサイズ 0 だったら終了\n",
    "    if scroll_size <= 0:\n",
    "        break\n",
    "\n",
    "    # 検索結果を処理\n",
    "#     get_doc(response['hits']['hits'])\n",
    "    hits = response['hits']['hits']\n",
    "    for hit in hits:\n",
    "        text = hit['_source']['sudachi']\n",
    "        print(f\"\\r{counter} {text}\", end=\"\")\n",
    "        counter += 1\n",
    "\n",
    "    # スクロールから次の検索結果取得\n",
    "    response = es.scroll(scroll_id=sid, scroll='10m')\n",
    "    scroll_size = len(response['hits']['hits'])\n",
    "#     print('scroll_size', scroll_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 17,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 5812, 'relation': 'eq'},\n",
       "  'max_score': 2.3869104,\n",
       "  'hits': [{'_index': 'jsai_dataset',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'hAtHAHMBF5bF-mInviF-',\n",
       "    '_score': 2.3869104,\n",
       "    '_source': {'category': 'メディアミックス',\n",
       "     'title': 'ゴルゴ13',\n",
       "     'text': '「別冊ゴルゴ」の巻数表示は、第1集から第28集までは巻数表示が一切ない。第29集から第167集までは裏表紙に小さく〔29〕のように、第64集以降は裏表紙に加えて本の背に No.64 のように、第168集以降は本の背に加えて裏表紙に No.168 のように表示されている。',\n",
       "     'sudachi': '別冊 ゴルゴ の 巻数 表示 は 第 1 集 から 第 28 集 まで は 巻数 表示 が 一切 ない 第 29 集 から 第 167 集 まで は 裏表紙 に 小さく 29 の よう に 第 64 集 以降 は 裏表紙 に 加え て 本 の 背 に no. 64 の よう に 第 168 集 以降 は 本 の 背 に 加え て 裏表紙 に no. 168 の よう に 表示 さ れ て いる'}},\n",
       "   {'_index': 'jsai_dataset',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'hQtHAHMBF5bF-mInviGG',\n",
       "    '_score': 2.3869104,\n",
       "    '_source': {'category': 'メディアミックス',\n",
       "     'title': 'ゴルゴ13',\n",
       "     'text': '「別冊ゴルゴ」では、1巻に7U分（たとえば前後編が2話と三部作が1話、のように）収録される。1Uを40ページとすると、約280ページ相当という勘定になる。実際の「別冊ゴルゴ」は、330ページほどのボリュームとなっており、この差は『ゴルゴ13』以外の他の作家の漫画分や広告、扉絵の再収録の分である。',\n",
       "     'sudachi': '別冊 ゴルゴ で は 1 巻 に 7 u 分 たとえば 前後編 が 2 話 と 三部作 が 1 話 の よう に 収録 さ れる 1 u を 40 ページ と する と 約 280 ページ 相当 と いう 勘定 に なる 実際 の 別冊 ゴルゴ は 330 ページ ほど の ボリューム と なっ て おり この 差 は ゴルゴ 13 以外 の 他 の 作家 の 漫画 分 や 広告 扉絵 の 再 収録 の 分 で ある'}},\n",
       "   {'_index': 'jsai_dataset',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'hgtHAHMBF5bF-mInviGM',\n",
       "    '_score': 2.3869104,\n",
       "    '_source': {'category': 'メディアミックス',\n",
       "     'title': 'ゴルゴ13',\n",
       "     'text': '「別冊ゴルゴ」は、以下のような特徴がある。',\n",
       "     'sudachi': '別冊 ゴルゴ は 以下 の よう な 特徴 が ある'}},\n",
       "   {'_index': 'jsai_dataset',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'hwtHAHMBF5bF-mInviGR',\n",
       "    '_score': 2.3869104,\n",
       "    '_source': {'category': 'メディアミックス',\n",
       "     'title': 'ゴルゴ13',\n",
       "     'text': '「別冊ゴルゴ」に収録されたエピソードは、約1年ほど経ってから小学館から『ビッグコミック増刊 ゴルゴ13総集編』として発刊される。以下、「増刊ゴルゴ」と表記する。',\n",
       "     'sudachi': '別冊 ゴルゴ に 収録 さ れ た エピソード は 約 1 年 ほど 経っ て から 小学館 から ビッグコミック 増刊 ゴルゴ 13 総集編 と し て 発刊 さ れる 以下 増刊 ゴルゴ と 表記 する'}},\n",
       "   {'_index': 'jsai_dataset',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'iAtHAHMBF5bF-mInviGY',\n",
       "    '_score': 2.3869104,\n",
       "    '_source': {'category': 'メディアミックス',\n",
       "     'title': 'ゴルゴ13',\n",
       "     'text': '「増刊ゴルゴ」は、1973年（昭和48年）1月15日に第1集が発行され、最新刊は2019年2月13日発売の第194集、収録作は「震える修験者」「寡黙なパートナー」「PTSD」の3作と、ほかにさいとう・たかを読みきり掘り出し市として他作品の読みきり一作が収録されている。JAN 4910296770395-00389。発売日は、2・5・8・11月の13日、税込み定価は420円である。B5サイズのホッチキス中綴じで、『ビッグコミック』と同じ体裁、同じ画面サイズになる。カバーはなく、ザラ紙に印刷されており、増刷はされない。',\n",
       "     'sudachi': '増刊 ゴルゴ は 1973 年 昭和 48 年 1 月 15 日 に 第 1 集 が 発行 さ れ 最新刊 は 2019 年 2 月 13 日 発売 の 第 194 集 収録 作 は 震える 修験者 寡黙 な パートナ ptsd の 3 作 と ほか に さいとう たか を 読み きり 掘り出し 市 と し て 他 作品 の 読みきり 1 作 が 収録 さ れ て いる jan 491029677039500389 発売日 は 25811 月 の 13 日 税込み 定価 は 420 円 で ある b 5 サイズ の ホッチキス 中 綴じ で ビッグコミック と 同じ 体裁 同じ 画面 サイズ に なる カバー は なく ザラ紙 に 印刷 さ れ て おり 増刷 は さ れ ない'}},\n",
       "   {'_index': 'jsai_dataset',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'iQtHAHMBF5bF-mInviGf',\n",
       "    '_score': 2.3869104,\n",
       "    '_source': {'category': 'メディアミックス',\n",
       "     'title': 'ゴルゴ13',\n",
       "     'text': '「増刊ゴルゴ」の巻数表示は「vol.194」のように表示されている。',\n",
       "     'sudachi': '増刊 ゴルゴ の 巻数 表示 は vol. 194 の よう に 表示 さ れ て いる'}},\n",
       "   {'_index': 'jsai_dataset',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'igtHAHMBF5bF-mInviGm',\n",
       "    '_score': 2.3869104,\n",
       "    '_source': {'category': 'メディアミックス',\n",
       "     'title': 'ゴルゴ13',\n",
       "     'text': '「増刊ゴルゴ」では、1巻に6U分（たとえば単発が1話と前後編が1話と三部作が1話、のように）収録される。1Uを40ページとすると、約240ページ相当という勘定になる。',\n",
       "     'sudachi': '増刊 ゴルゴ で は 1 巻 に 6 u 分 たとえば 単発 が 1 話 と 前後編 が 1 話 と 三部作 が 1 話 の よう に 収録 さ れる 1 u を 40 ページ と する と 約 240 ページ 相当 と いう 勘定 に なる'}},\n",
       "   {'_index': 'jsai_dataset',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'iwtHAHMBF5bF-mInviG0',\n",
       "    '_score': 2.3869104,\n",
       "    '_source': {'category': 'メディアミックス',\n",
       "     'title': 'ゴルゴ13',\n",
       "     'text': '「増刊ゴルゴ」は、以下のような特徴がある。',\n",
       "     'sudachi': '増刊 ゴルゴ は 以下 の よう な 特徴 が ある'}},\n",
       "   {'_index': 'jsai_dataset',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'jAtHAHMBF5bF-mInviG-',\n",
       "    '_score': 2.3869104,\n",
       "    '_source': {'category': 'メディアミックス',\n",
       "     'title': 'ゴルゴ13',\n",
       "     'text': '「増刊ゴルゴ」に収録されたエピソードは、約1年ほど経ってからリイド社から『SPコミックス ゴルゴ13』として発刊される。以下、「SPゴルゴ」と表記する（リイド社は元々さいとう・プロの出版部門が源流で、SPはさいとう・プロの略）。',\n",
       "     'sudachi': '増刊 ゴルゴ に 収録 さ れ た エピソード は 約 1 年 ほど 経っ て から リイド 社 から sp コミックス ゴルゴ 13 と し て 発刊 さ れる 以下 sp ゴルゴ と 表記 する リイド 社 は 元元 さいとう プロ の 出版 部門 が 源流 で sp は さいとう プロ の 略'}},\n",
       "   {'_index': 'jsai_dataset',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'jQtHAHMBF5bF-mInviHG',\n",
       "    '_score': 2.3869104,\n",
       "    '_source': {'category': 'メディアミックス',\n",
       "     'title': 'ゴルゴ13',\n",
       "     'text': '「SPゴルゴ」の発売日は、4・7・9・12月の5日、価格は税別593円である。サイズはいわゆる「おとなマンガ」のサイズで、小学館のビッグコミックスのサイズと同じである。',\n",
       "     'sudachi': 'sp ゴルゴ の 発売日 は 47912 月 の 5 日 価格 は 税別 593 円 で ある サイズ は いわゆる おとな マンガ の サイズ で 小学館 の ビッグコミックス の サイズ と 同じ で ある'}}]}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
