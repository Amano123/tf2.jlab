{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import glob\n",
    "import re\n",
    "import io \n",
    "import os\n",
    "\n",
    "file_name_path = \"./jsai/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのy意味込み\n",
    "import requests\n",
    "\n",
    "# メッセージ送信、画像送信、スタンプ送信の処理をクラス化\n",
    "class LINENotifyBot:\n",
    "    API_URL = 'https://notify-api.line.me/api/notify'\n",
    "    def __init__(self, access_token):\n",
    "        self.__headers = {'Authorization': 'Bearer ' + access_token}\n",
    "\n",
    "    def send(\n",
    "            self, message,\n",
    "            image=None, sticker_package_id=None, sticker_id=None,\n",
    "            ):\n",
    "        payload = {\n",
    "            'message': message,\n",
    "            'stickerPackageId': sticker_package_id,\n",
    "            'stickerId': sticker_id,\n",
    "            }\n",
    "        files = {}\n",
    "        if image != None:\n",
    "            files = {'imageFile': open(image, 'rb')}\n",
    "        r = requests.post(\n",
    "            LINENotifyBot.API_URL,\n",
    "            headers=self.__headers,\n",
    "            data=payload,\n",
    "            files=files,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = LINENotifyBot(access_token='luTtDSuF8bgeUBZoPDyA6s44vHlQO2ptwIWGM8dW7Yp')\n",
    "def LINE(text):\n",
    "    bot.send(message=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir(file_name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_create(file_name_path, file_names):\n",
    "    '''\n",
    "    dict_create\n",
    "    * file_name_path :root path\n",
    "    * file_names     :file name list\n",
    "    ファイルの読み込みをわかりやすくするために辞書型のデータを作成\n",
    "    フォルダ名：ファイル名の関係にしてある\n",
    "    '''\n",
    "    data_dict = {}\n",
    "    for name in file_names:\n",
    "        if os.path.isdir(file_name_path + name):\n",
    "            #data_dict[name] = glob.glob(file_name_path + name + \"/txt/*.txt\")\n",
    "            name_list = os.listdir(file_name_path + name + \"/txt/\")\n",
    "            data_dict[name] = [i for i in name_list if i[-4:] == \".txt\"]\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting():\n",
    "    settings = {\n",
    "        \"settings\": {\n",
    "            \"analysis\": {\n",
    "                \"filter\": {\n",
    "                    \"synonyms_filter\": { # 同義語フィルターの定義\n",
    "                        \"type\": \"synonym\",\n",
    "                        \"synonyms\": [ #同義語リストの定義 (今は空の状態)\n",
    "                            ]\n",
    "                    }\n",
    "                },\n",
    "                \"tokenizer\": {\n",
    "                    \"sudachi_tokenizer\": {\n",
    "                        \"type\": \"sudachi_tokenizer\",\n",
    "                        \"discard_punctuation\": True,\n",
    "                        \"sudachi_split\": \"search\",\n",
    "                        \"resources_path\": \"/usr/share/elasticsearch/config/sudachi\",\n",
    "                        \"settings_path\": \"/usr/share/elasticsearch/config/sudachi/sudachi_fulldict.json\"\n",
    "                    }\n",
    "                },\n",
    "                \"analyzer\": {\n",
    "                    \"sudachi_analyzer\": {\n",
    "                        \"char_filter\": [\n",
    "                            \"icu_normalizer\", # 文字単位の正規化\n",
    "                            \"kuromoji_iteration_mark\" # 繰り返し文字の正規化\n",
    "                        ],\n",
    "                        \"filter\": [\n",
    "                            \"synonyms_filter\", # 同義語展開\n",
    "                            # \"kuromoji_baseform\", # 活用語の原型化\n",
    "                            # \"kuromoji_part_of_speech\", # 不要品詞の除去\n",
    "                            # \"ja_stop\", #不要単語の除去\n",
    "                            \"kuromoji_number\", # 数字の正規化\n",
    "                            \"kuromoji_stemmer\" #長音の正規化\n",
    "                        ],\n",
    "                        \"tokenizer\": \"sudachi_tokenizer\",\n",
    "                        \"type\": \"custom\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"category\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "                \"title\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "                \"text\": {\n",
    "                    \"analyzer\": \"sudachi_analyzer\",\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                \"sudachi\": {\n",
    "                    \"type\": \"text\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_es(index_name, es_host_name, setting):\n",
    "    es = Elasticsearch(es_host_name)\n",
    "    if es.indices.exists(index=index_name):\n",
    "        print(f\"{index_name}を更新します。\")\n",
    "        es.indices.delete(index=index_name)\n",
    "    result = es.indices.create(index=index_name, body=setting)\n",
    "    if result[\"acknowledged\"]:\n",
    "        print(f'create index【{result[\"index\"]}】')\n",
    "        return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jsai_datasetを更新します。\n",
      "create index【jsai_dataset】\n"
     ]
    }
   ],
   "source": [
    "data_dict = dict_create(file_name_path, file_names)\n",
    "es_name = \"jsai_dataset\"\n",
    "es_host_name = \"elasticsearch-sudachi\"\n",
    "es = create_es(es_name, es_host_name, setting())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_word(text):\n",
    "    # 文末の改行を削除\n",
    "    text_data = re.sub(\"\\n+$\", \"\", text)\n",
    "    text_data = text_data.split(\",\")\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_datas(es, index_name, category, file_names):\n",
    "    for name in file_names:\n",
    "        original_data = io.open(f\"./jsai/{category}/txt/{name}\",mode=\"r\", encoding=\"utf-8\").read()\n",
    "        datas = stop_word(original_data)\n",
    "        for num, data in enumerate(datas, 1):\n",
    "            print(f\"\\r{category}:{name[:-4]} {num}\", end=\"\")\n",
    "            analyze_body = {\"text\": data, \"analyzer\": \"sudachi_analyzer\"}\n",
    "            sudachi_morp = es.indices.analyze(index=index_name, body=analyze_body)[\"tokens\"]\n",
    "            sudachi_token = \" \".join([word[\"token\"] for word in sudachi_morp])\n",
    "            body = {\n",
    "                \"category\": category,\n",
    "                \"title\": name[:-4],\n",
    "                \"text\": data,\n",
    "                \"sudachi\": sudachi_token\n",
    "            }\n",
    "            es.index(index=index_name, body=body)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "メディアミックス:ジュラシック・パーク 45バース 5 27 697\n",
      "finished メディアミックス\n",
      "アニメ:がきデカ 305fe 8レラガールズ (アニメ) 34ana Famiglia- 138\n",
      "finished アニメ\n",
      "公開企業:カーリットホールディングス 6ン 2116ク・カンパニー 6\n",
      "finished 公開企業\n",
      "食品:ハーリング (料理) 940゙ 10\n",
      "finished 食品\n",
      "アーティスト:ボストン (バンド) 15ニー 6・バンド 12 6ates of America 4\n",
      "finished アーティスト\n",
      "おもちゃ:メリーゴーラウンド 86ラー 5\n",
      "finished おもちゃ\n",
      "ゲーム:シャドウハンターズ 12ンカードゲーム 1\n",
      "finished ゲーム\n",
      "バイク:デグナー 30 25 607ーグ) 23on 9の科学者・成海朔の挑戦〜 6ER 3\n",
      "finished バイク\n",
      "ドリンク:ポスカ (飲料) 5 8スキー) 11\n",
      "finished ドリンク\n",
      "自動車:ベントレー・4¼リットル 954 24 4\n",
      "finished 自動車\n"
     ]
    }
   ],
   "source": [
    "for category in data_dict:\n",
    "    LINE(f\"\\n{category} start\")\n",
    "    input_datas(es, es_name, category, data_dict[category])\n",
    "    print(f\"finished {category}\")\n",
    "    LINE(f\"\\n{category} end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINE(f\"おわったよ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "メディアミックス\n",
      "total {'value': 5812, 'relation': 'eq'}\n",
      "アニメ\n",
      "total {'value': 4030, 'relation': 'eq'}\n",
      "公開企業\n",
      "total {'value': 2721, 'relation': 'eq'}\n",
      "食品\n",
      "total {'value': 657, 'relation': 'eq'}\n",
      "アーティスト\n",
      "total {'value': 4953, 'relation': 'eq'}\n",
      "おもちゃ\n",
      "total {'value': 516, 'relation': 'eq'}\n",
      "ゲーム\n",
      "total {'value': 814, 'relation': 'eq'}\n",
      "バイク\n",
      "total {'value': 10000, 'relation': 'gte'}\n",
      "ドリンク\n",
      "total {'value': 154, 'relation': 'eq'}\n",
      "自動車\n",
      "total {'value': 372, 'relation': 'eq'}\n"
     ]
    }
   ],
   "source": [
    "for category in data_dict:\n",
    "    print(category)\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"term\": {\n",
    "                \"category\": category\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    result = es.search(\n",
    "            index=es_name,\n",
    "            body=body\n",
    "    )\n",
    "    print('total', result['hits']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in data_dict:\n",
    "    LINE(f\"\\n{category} start\")\n",
    "    response = es.search(\n",
    "                    scroll='2m',\n",
    "                    size=10000,\n",
    "                    index=es_name,\n",
    "                    body={\n",
    "                        \"query\": {\n",
    "                            \"term\": {\n",
    "                                \"category\": category\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "    sid = response['_scroll_id']\n",
    "    # print('sid', sid)\n",
    "    # print('total', response['hits']['total'])\n",
    "\n",
    "    scroll_size = len(response['hits']['hits'])\n",
    "    # print('scroll_size', scroll_size)\n",
    "    open(f\"./sudachi_dataset/{category}.txt\", mode=\"x\", encoding=\"utf-8\")\n",
    "    counter = 1\n",
    "    while True:\n",
    "        # スクロールサイズ 0 だったら終了\n",
    "        if scroll_size <= 0:\n",
    "            break\n",
    "\n",
    "        # 検索結果を処理\n",
    "    #     get_doc(response['hits']['hits'])\n",
    "        hits = response['hits']['hits']\n",
    "        for hit in hits:\n",
    "            text = hit['_source']['sudachi']\n",
    "            text = re.sub(r\"([0-9]+) (年) \", r\"\\1\\2 \", text)\n",
    "            if len(text.split()) < 10 :\n",
    "                continue\n",
    "    #             print(f\"{counter} {text}\", end=\"\")\n",
    "            with open(f\"./sudachi_dataset/{category}.txt\", mode=\"a\", encoding=\"utf-8\") as save_file:\n",
    "                save_file.write(text + \"\\n\")\n",
    "            counter += 1\n",
    "\n",
    "        # スクロールから次の検索結果取得\n",
    "        response = es.scroll(scroll_id=sid, scroll='10m')\n",
    "        scroll_size = len(response['hits']['hits'])\n",
    "    #     print('scroll_size', scroll_size)\n",
    "    LINE(f\"\\n{category} end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "while True:\n",
    "    # スクロールサイズ 0 だったら終了\n",
    "    if scroll_size <= 0:\n",
    "        break\n",
    "\n",
    "    # 検索結果を処理\n",
    "#     get_doc(response['hits']['hits'])\n",
    "    hits = response['hits']['hits']\n",
    "    for hit in hits:\n",
    "        text = hit['_source']['sudachi']\n",
    "        print(f\"\\r{counter} {text}\", end=\"\")\n",
    "        counter += 1\n",
    "\n",
    "    # スクロールから次の検索結果取得\n",
    "    response = es.scroll(scroll_id=sid, scroll='10m')\n",
    "    scroll_size = len(response['hits']['hits'])\n",
    "#     print('scroll_size', scroll_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
